{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edfc004a-05d5-482e-a24d-c7b7c93a785a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import RussianStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer,  TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9111e293-5437-4e42-bdd9-2499765d2702",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('rusentitweet_train.csv')\n",
    "X_test = pd.read_csv('rusentitweet_test.csv')\n",
    "X_train = X_train[X_train.label.isin(['positive','negative'])]\n",
    "X_train = X_train.drop('id', axis=1).replace(['positive'], 1).replace(['negative'], 0)\n",
    "X_test = X_test[X_test.label.isin(['positive','negative'])]\n",
    "X_test = X_test.drop('id', axis=1).replace(['positive'], 1).replace(['negative'], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a32a1fb-80fc-4d0a-9509-0f69147a9927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Изменение регистра, удаление пунктуации и спец.символов\n",
    "def cleaning(str):\n",
    "    str = str.lower()\n",
    "    # Чистка от ссылок\n",
    "    str = re.sub(r'http\\S+', '', str)\n",
    "    # Чистка от табуляции, переноса строки и т.д.\n",
    "    str = re.sub(r'\\r|\\n|\\t|_|\\\\u', ' ', str)\n",
    "    # Чистка от тэгов\n",
    "    str = re.sub(r'\\@\\S*', '', str)\n",
    "    # Чистка от символов\n",
    "    str = re.sub(r'[()/,.0-9%#-?!`\\'—]', '', str)\n",
    "    \n",
    "    # str = re.sub(r'', '', str)\n",
    "    return str\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "493e3ac9-fb4e-4016-be21-dafdf331c41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Стемминг\n",
    "stemmer = RussianStemmer()\n",
    "def stem_words(words):\n",
    "    return [stemmer.stem(word) for word in words]\n",
    "\n",
    "def preprocess_tweet(tweet):\n",
    "    tweet = cleaning(tweet)\n",
    "    # Tokenize the tweet\n",
    "    words = nltk.word_tokenize(tweet)\n",
    "    words = stem_words(words)\n",
    "    # Return the preprocessed tweet as a string\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86c7652f-629d-4d3c-9c2f-f4a14302b797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Применение методов\n",
    "milled_train = list(map(preprocess_tweet, X_train.text))\n",
    "milled_test = list(map(preprocess_tweet, X_test.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bef74f4e-f32c-4b00-a83b-863ecf08f547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the CountVectorizer from sklearn to convert the preprocessed tweets into a bag of words\n",
    "vectorizer = CountVectorizer()\n",
    "# Preprocess the train tweets and convert them into a bag of words\n",
    "train_tweets_bow = vectorizer.fit_transform(milled_train)\n",
    "# Preprocess the test tweets and convert them into a bag of words using the same vectorizer\n",
    "test_tweets_bow = vectorizer.transform(milled_test)\n",
    "\n",
    "# Calculate the tf-idf\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidf_matrix = tfidf_transformer.fit(train_tweets_bow)\n",
    "\n",
    "x_tf_idf_train = tfidf_matrix.transform(train_tweets_bow)\n",
    "x_tf_idf_test = tfidf_matrix.transform(test_tweets_bow)\n",
    "\n",
    "# vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5320d9f-eb40-4819-843f-0abd6d222f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report of Logistic Regression:\n",
      "0.9096082293718538 0.773403324584427\n",
      "Classification Report of Random Forest:\n",
      "0.9991245349091705 0.7462817147856518\n"
     ]
    }
   ],
   "source": [
    "# Обучение моделей\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_tf_idf_train, X_train.label)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_tf_idf_train, X_train.label)\n",
    "\n",
    "y_lr_train = lr.score(x_tf_idf_train, X_train.label)\n",
    "y_rf_train = rf.score(x_tf_idf_train, X_train.label)\n",
    "# Оценка качества моделей на тестовых данных\n",
    "y_lr_test = lr.score(x_tf_idf_test, X_test.label)\n",
    "y_rf_test = rf.score(x_tf_idf_test, X_test.label)\n",
    "\n",
    "# Предикты\n",
    "y_pred_lr_train = lr.predict(x_tf_idf_train)\n",
    "y_pred_rf_train = rf.predict(x_tf_idf_train)\n",
    "# Оценка качества моделей на тестовых данных\n",
    "y_pred_lr_test = lr.predict(x_tf_idf_test)\n",
    "y_pred_rf_test = rf.predict(x_tf_idf_test)\n",
    "\n",
    "# Отчет о классификации\n",
    "print('Classification Report of Logistic Regression:')\n",
    "print(y_lr_train, y_lr_test)\n",
    "\n",
    "print('Classification Report of Random Forest:')\n",
    "print(y_rf_train, y_rf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60e0e0c6-3a2f-44c3-997c-66da22d3008e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "любл      3.51\n",
      "хорош     3.38\n",
      "красив    3.07\n",
      "нрав      2.74\n",
      "крут      2.66\n",
      "          ... \n",
      "нах      -2.43\n",
      "пиздец   -2.85\n",
      "нет      -2.89\n",
      "блят     -3.32\n",
      "не       -3.46\n",
      "Length: 8997, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(pd.Series(lr.coef_[0], index = vectorizer.get_feature_names_out()).sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2074c822-5afd-448f-9d0e-a385aae5f01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Type  Accuracy  Precision\n",
      "0   randf_train      1.00       1.00\n",
      "1    randf_test      0.75       0.74\n",
      "0  logreg_train      0.91       0.92\n",
      "1   logreg_test      0.77       0.80\n"
     ]
    }
   ],
   "source": [
    "# Вычисление метрик для логистической регрессии\n",
    "data_logreg = {\n",
    "    'Type': ['logreg_train', 'logreg_test'],\n",
    "    'Accuracy': [accuracy_score(X_train.label, y_pred_lr_train), accuracy_score(X_test.label, y_pred_lr_test)], \n",
    "    'Precision': [precision_score(X_train.label, y_pred_lr_train, average='macro'), precision_score(X_test.label, y_pred_lr_test, average='macro')], \n",
    "}\n",
    "\n",
    "# Вычисление метрик для случайного леса\n",
    "data_forest = {\n",
    "    'Type': ['randf_train', 'randf_test'],\n",
    "    'Accuracy': [accuracy_score(X_train.label, y_pred_rf_train), accuracy_score(X_test.label, y_pred_rf_test)], \n",
    "    'Precision': [precision_score(X_train.label, y_pred_rf_train, average='macro'), precision_score(X_test.label, y_pred_rf_test, average='macro')], \n",
    "}\n",
    "\n",
    "print(pd.concat([pd.DataFrame(data_forest), pd.DataFrame(data_logreg)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e18aee-0e9e-4c53-adc2-619c4f2970b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymystem3\n",
    "\n",
    "X_train = X_train.head(100)\n",
    "X_test = X_test.head(100)\n",
    "\n",
    "# Initialize the lemmatizer\n",
    "mystem = pymystem3.Mystem()\n",
    "\n",
    "def preprocess_tweet(tweet):\n",
    "    tweet = cleaning(tweet)\n",
    "    lemmas = mystem.lemmatize(tweet)\n",
    "    return ' '.join(lemmas)\n",
    "\n",
    "# Применение методов\n",
    "milled_train = list(map(preprocess_tweet, X_train.text))\n",
    "milled_test = list(map(preprocess_tweet, X_test.text))\n",
    "\n",
    "# Initialize the CountVectorizer from sklearn to convert the preprocessed tweets into a bag of words\n",
    "vectorizer = CountVectorizer()\n",
    "# Preprocess the train tweets and convert them into a bag of words\n",
    "train_tweets_bow = vectorizer.fit_transform(milled_train)\n",
    "# Preprocess the test tweets and convert them into a bag of words using the same vectorizer\n",
    "test_tweets_bow = vectorizer.transform(milled_test)\n",
    "\n",
    "# Calculate the tf-idf\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidf_matrix = tfidf_transformer.fit(train_tweets_bow)\n",
    "\n",
    "x_tf_idf_train = tfidf_matrix.transform(train_tweets_bow)\n",
    "x_tf_idf_test = tfidf_matrix.transform(test_tweets_bow)\n",
    "\n",
    "# vectorizer.get_feature_names_out()\n",
    "# Обучение моделей\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_tf_idf_train, X_train.label)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_tf_idf_train, X_train.label)\n",
    "\n",
    "y_lr_train = lr.score(x_tf_idf_train, X_train.label)\n",
    "y_rf_train = rf.score(x_tf_idf_train, X_train.label)\n",
    "# Оценка качества моделей на тестовых данных\n",
    "y_lr_test = lr.score(x_tf_idf_test, X_test.label)\n",
    "y_rf_test = rf.score(x_tf_idf_test, X_test.label)\n",
    "\n",
    "# Предикты\n",
    "y_pred_lr_train = lr.predict(x_tf_idf_train)\n",
    "y_pred_rf_train = rf.predict(x_tf_idf_train)\n",
    "# Оценка качества моделей на тестовых данных\n",
    "y_pred_lr_test = lr.predict(x_tf_idf_test)\n",
    "y_pred_rf_test = rf.predict(x_tf_idf_test)\n",
    "\n",
    "# Отчет о классификации\n",
    "print('Classification Report of Logistic Regression:')\n",
    "print(y_lr_train, y_lr_test)\n",
    "\n",
    "print('Classification Report of Random Forest:')\n",
    "print(y_rf_train, y_rf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "530677f8-9376-4b7c-a648-ac3a929e3650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "любл      3.51\n",
      "хорош     3.38\n",
      "красив    3.07\n",
      "нрав      2.74\n",
      "крут      2.66\n",
      "          ... \n",
      "нах      -2.43\n",
      "пиздец   -2.85\n",
      "нет      -2.89\n",
      "блят     -3.32\n",
      "не       -3.46\n",
      "Length: 8997, dtype: float64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [100, 4569]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(pd\u001b[38;5;241m.\u001b[39mSeries(lr\u001b[38;5;241m.\u001b[39mcoef_[\u001b[38;5;241m0\u001b[39m], index \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mget_feature_names_out())\u001b[38;5;241m.\u001b[39msort_values(ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Вычисление метрик для логистической регрессии\u001b[39;00m\n\u001b[0;32m      4\u001b[0m data_logreg \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mType\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogreg_train\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogreg_test\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_lr_train\u001b[49m\u001b[43m)\u001b[49m, accuracy_score(X_test\u001b[38;5;241m.\u001b[39mlabel, y_pred_lr_test)], \n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrecision\u001b[39m\u001b[38;5;124m'\u001b[39m: [precision_score(X_train\u001b[38;5;241m.\u001b[39mlabel, y_pred_lr_train, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m), precision_score(X_test\u001b[38;5;241m.\u001b[39mlabel, y_pred_lr_test, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m)], \n\u001b[0;32m      8\u001b[0m }\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Вычисление метрик для случайного леса\u001b[39;00m\n\u001b[0;32m     11\u001b[0m data_forest \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mType\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandf_train\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandf_test\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m: [accuracy_score(X_train\u001b[38;5;241m.\u001b[39mlabel, y_pred_rf_train), accuracy_score(X_test\u001b[38;5;241m.\u001b[39mlabel, y_pred_rf_test)], \n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrecision\u001b[39m\u001b[38;5;124m'\u001b[39m: [precision_score(X_train\u001b[38;5;241m.\u001b[39mlabel, y_pred_rf_train, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m), precision_score(X_test\u001b[38;5;241m.\u001b[39mlabel, y_pred_rf_test, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m)], \n\u001b[0;32m     15\u001b[0m }\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:213\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \n\u001b[0;32m    149\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 213\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:85\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \n\u001b[0;32m     61\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 85\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     87\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:430\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    428\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    429\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 430\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    431\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    432\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    433\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [100, 4569]"
     ]
    }
   ],
   "source": [
    "print(pd.Series(lr.coef_[0], index = vectorizer.get_feature_names_out()).sort_values(ascending=False))\n",
    "\n",
    "# Вычисление метрик для логистической регрессии\n",
    "data_logreg = {\n",
    "    'Type': ['logreg_train', 'logreg_test'],\n",
    "    'Accuracy': [accuracy_score(X_train.label, y_pred_lr_train), accuracy_score(X_test.label, y_pred_lr_test)], \n",
    "    'Precision': [precision_score(X_train.label, y_pred_lr_train, average='macro'), precision_score(X_test.label, y_pred_lr_test, average='macro')], \n",
    "}\n",
    "\n",
    "# Вычисление метрик для случайного леса\n",
    "data_forest = {\n",
    "    'Type': ['randf_train', 'randf_test'],\n",
    "    'Accuracy': [accuracy_score(X_train.label, y_pred_rf_train), accuracy_score(X_test.label, y_pred_rf_test)], \n",
    "    'Precision': [precision_score(X_train.label, y_pred_rf_train, average='macro'), precision_score(X_test.label, y_pred_rf_test, average='macro')], \n",
    "}\n",
    "\n",
    "print(pd.concat([pd.DataFrame(data_forest), pd.DataFrame(data_logreg)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddeaf90-309d-4d04-aab8-79ad6e66aaea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
